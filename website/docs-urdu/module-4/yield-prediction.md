---
sidebar_position: 3
---

# Ù¾ÛŒØ¯Ø§ÙˆØ§Ø± Ù¾ÛŒØ´ Ú¯ÙˆØ¦ÛŒ Ù…Ø§ÚˆÙ„Ø²

## ØªØ¹Ø§Ø±Ù

ÙØµÙ„ Ú©ÛŒ Ù¾ÛŒØ¯Ø§ÙˆØ§Ø± Ù¾ÛŒØ´ Ú¯ÙˆØ¦ÛŒ Ú©Ø³Ø§Ù†ÙˆÚº Ú©Ùˆ Ø¨ÛØªØ± ÙÛŒØµÙ„Û’ Ú©Ø±Ù†Û’ Ù…ÛŒÚº Ù…Ø¯Ø¯ Ø¯ÛŒØªÛŒ ÛÛ’Û” ML Ù…Ø§ÚˆÙ„Ø² Ø³ÛŒÙ†Ø³Ø± ÚˆÛŒÙ¹Ø§ØŒ Ù…ÙˆØ³Ù…ØŒ Ø§ÙˆØ± ØªØ§Ø±ÛŒØ®ÛŒ ÚˆÛŒÙ¹Ø§ Ø³Û’ Ù¾ÛŒØ¯Ø§ÙˆØ§Ø± Ú©Ø§ Ø§Ù†Ø¯Ø§Ø²Û Ù„Ú¯Ø§ØªÛ’ ÛÛŒÚº ğŸŒ¾ğŸ“ˆÛ”

## ÚˆÛŒÙ¹Ø§ Ú©ÛŒ Ø§Ù‚Ø³Ø§Ù…

| ÚˆÛŒÙ¹Ø§ | Ø°Ø±ÛŒØ¹Û | Ø§ÛÙ…ÛŒØª |
|------|-------|-------|
| Ù…ÙˆØ³Ù…ÛŒ | ÙˆÛŒØ¯Ø± Ø³Ù¹ÛŒØ´Ù† | Ø¨ÛØª Ø²ÛŒØ§Ø¯Û |
| Ù…Ù¹ÛŒ | Ø³ÛŒÙ†Ø³Ø±Ø² | Ø²ÛŒØ§Ø¯Û |
| Ø³ÛŒÙ¹Ù„Ø§Ø¦Ù¹ | NDVI | Ø²ÛŒØ§Ø¯Û |
| ØªØ§Ø±ÛŒØ®ÛŒ | Ø±ÛŒÚ©Ø§Ø±ÚˆØ² | Ø¯Ø±Ù…ÛŒØ§Ù†ÛŒ |

## ÚˆÛŒÙ¹Ø§ Ø³ÛŒÙ¹ ØªÛŒØ§Ø±ÛŒ

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

# Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØµÙ„ ÚˆÛŒÙ¹Ø§
np.random.seed(42)
n_samples = 500

data = {
    'temperature_avg': np.random.uniform(15, 35, n_samples),
    'rainfall': np.random.uniform(0, 300, n_samples),
    'humidity_avg': np.random.uniform(40, 90, n_samples),
    'soil_ph': np.random.uniform(5.5, 8.0, n_samples),
    'nitrogen': np.random.uniform(0, 150, n_samples),
    'phosphorus': np.random.uniform(0, 100, n_samples),
    'potassium': np.random.uniform(0, 200, n_samples),
    'ndvi_avg': np.random.uniform(0.2, 0.9, n_samples),
}

# Ù¾ÛŒØ¯Ø§ÙˆØ§Ø± Ú©ÛŒÙ„Ú©ÙˆÙ„ÛŒÙ¹ Ú©Ø±ÛŒÚº (Ú©ÙˆØ¦Ù†Ù¹Ù„/Ø§ÛŒÚ©Ú‘)
data['yield'] = (
    20 + 
    0.5 * data['temperature_avg'] +
    0.02 * data['rainfall'] +
    0.1 * data['humidity_avg'] +
    -2 * np.abs(data['soil_ph'] - 6.5) +
    0.05 * data['nitrogen'] +
    10 * data['ndvi_avg'] +
    np.random.normal(0, 3, n_samples)
)

df = pd.DataFrame(data)
print(df.describe())
```

## ÙÛŒÚ†Ø± Ø§Ù†Ø¬ÛŒÙ†Ø¦Ø±Ù†Ú¯

```python
def create_features(df):
    """
    Ù†Ø¦Û’ ÙÛŒÚ†Ø±Ø² Ø¨Ù†Ø§Ø¦ÛŒÚº
    """
    df = df.copy()
    
    # Ø§Ù†Ù¹Ø±Ø§ÛŒÚ©Ø´Ù†Ø²
    df['temp_rainfall'] = df['temperature_avg'] * df['rainfall']
    df['npk_total'] = df['nitrogen'] + df['phosphorus'] + df['potassium']
    
    # ØªÙ†Ø§Ø³Ø¨
    df['n_p_ratio'] = df['nitrogen'] / (df['phosphorus'] + 1)
    
    # Ú©ÛŒÙ¹ÛŒÚ¯ÙˆØ±ÛŒ
    df['temp_category'] = pd.cut(df['temperature_avg'], 
                                  bins=[0, 20, 25, 30, 50],
                                  labels=['Ø³Ø±Ø¯', 'Ù…Ø¹ØªØ¯Ù„', 'Ú¯Ø±Ù…', 'Ø¨ÛØª Ú¯Ø±Ù…'])
    
    # Ø¯Ø±Ø¬Û Ø­Ø±Ø§Ø±Øª Ø§ÙˆÙ†Ú†Ø§/Ù†ÛŒÚ†Ø§
    df['is_optimal_temp'] = ((df['temperature_avg'] >= 20) & 
                              (df['temperature_avg'] <= 30)).astype(int)
    
    return df

df_features = create_features(df)
print(f"ÙÛŒÚ†Ø±Ø² Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯: {df_features.shape[1]}")
```

## Ù…Ø§ÚˆÙ„ 1: Random Forest

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# ÙÛŒÚ†Ø±Ø² Ø§ÙˆØ± Ù¹Ø§Ø±Ú¯Ù¹
feature_cols = ['temperature_avg', 'rainfall', 'humidity_avg', 
                'soil_ph', 'nitrogen', 'phosphorus', 'potassium', 'ndvi_avg']

X = df[feature_cols]
y = df['yield']

# ØªÙ‚Ø³ÛŒÙ…
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Ù…Ø§ÚˆÙ„
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    random_state=42
)

rf_model.fit(X_train, y_train)

# Ù¾ÛŒØ´ Ú¯ÙˆØ¦ÛŒ
y_pred_rf = rf_model.predict(X_test)

# Ù†ØªØ§Ø¦Ø¬
print(f"RÂ² Ø³Ú©ÙˆØ±: {r2_score(y_test, y_pred_rf):.3f}")
print(f"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.2f}")

# ÙÛŒÚ†Ø± Ø§ÛÙ…ÛŒØª
importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nÙÛŒÚ†Ø± Ø§ÛÙ…ÛŒØª:")
print(importance)
```

## Ù…Ø§ÚˆÙ„ 2: Gradient Boosting

```python
from sklearn.ensemble import GradientBoostingRegressor

gb_model = GradientBoostingRegressor(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    random_state=42
)

gb_model.fit(X_train, y_train)
y_pred_gb = gb_model.predict(X_test)

print(f"Gradient Boosting RÂ²: {r2_score(y_test, y_pred_gb):.3f}")
print(f"Gradient Boosting RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_gb)):.2f}")
```

## Ù…Ø§ÚˆÙ„ 3: Ù†ÛŒÙˆØ±Ù„ Ù†ÛŒÙ¹ÙˆØ±Ú©

```python
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import StandardScaler

# Ù†Ø§Ø±Ù…Ù„Ø§Ø¦Ø² Ú©Ø±ÛŒÚº
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Ù…Ø§ÚˆÙ„
def build_yield_predictor(input_dim):
    model = models.Sequential([
        layers.Dense(64, activation='relu', input_shape=(input_dim,)),
        layers.BatchNormalization(),
        layers.Dropout(0.2),
        
        layers.Dense(32, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.2),
        
        layers.Dense(16, activation='relu'),
        
        layers.Dense(1)
    ])
    
    model.compile(
        optimizer='adam',
        loss='mse',
        metrics=['mae']
    )
    
    return model

nn_model = build_yield_predictor(X_train.shape[1])

# Ù¹Ø±ÛŒÙ†Ù†Ú¯
history = nn_model.fit(
    X_train_scaled, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
    ],
    verbose=0
)

y_pred_nn = nn_model.predict(X_test_scaled).flatten()
print(f"Neural Network RÂ²: {r2_score(y_test, y_pred_nn):.3f}")
```

## Ù¹Ø§Ø¦Ù… Ø³ÛŒØ±ÛŒØ² Ù¾ÛŒØ´ Ú¯ÙˆØ¦ÛŒ

```python
from sklearn.linear_model import LinearRegression

def create_time_features(dates):
    """
    ØªØ§Ø±ÛŒØ® Ø³Û’ ÙÛŒÚ†Ø±Ø²
    """
    df = pd.DataFrame({'date': dates})
    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['day_of_year'] = df['date'].dt.dayofyear
    df['season'] = df['month'].apply(lambda x: 
        'Ø¨ÛØ§Ø±' if x in [3,4,5] else
        'Ú¯Ø±Ù…ÛŒ' if x in [6,7,8] else
        'Ø®Ø²Ø§Úº' if x in [9,10,11] else 'Ø³Ø±Ø¯ÛŒ')
    
    return df

# Ù…ÙˆØ³Ù…ÛŒ Ø±Ø¬Ø­Ø§Ù†
def seasonal_yield_model(historical_data):
    """
    Ù…ÙˆØ³Ù…ÛŒ Ù¾ÛŒØ¯Ø§ÙˆØ§Ø± Ù…Ø§ÚˆÙ„
    """
    # Ù…ÛÛŒÙ†Û’ Ú©ÛŒ Ø§ÙˆØ³Ø·
    monthly_avg = historical_data.groupby('month')['yield'].mean()
    
    # Ù¹Ø±ÛŒÙ†Úˆ
    yearly_avg = historical_data.groupby('year')['yield'].mean()
    
    return {
        'monthly_pattern': monthly_avg,
        'yearly_trend': yearly_avg
    }
```

## Ø§Ù†Ø³Ù…Ø¨Ù„ Ù…Ø§ÚˆÙ„

```python
class YieldEnsemble:
    def __init__(self):
        self.models = {}
        self.weights = {}
    
    def add_model(self, name, model, weight=1.0):
        self.models[name] = model
        self.weights[name] = weight
    
    def fit(self, X, y):
        for name, model in self.models.items():
            model.fit(X, y)
    
    def predict(self, X):
        predictions = {}
        
        for name, model in self.models.items():
            predictions[name] = model.predict(X)
        
        # ÙˆØ²Ù†ÛŒ Ø§ÙˆØ³Ø·
        total_weight = sum(self.weights.values())
        ensemble_pred = np.zeros(len(X))
        
        for name, pred in predictions.items():
            ensemble_pred += self.weights[name] * pred / total_weight
        
        return ensemble_pred

# Ø§Ø³ØªØ¹Ù…Ø§Ù„
ensemble = YieldEnsemble()
ensemble.add_model('rf', RandomForestRegressor(n_estimators=50), weight=2)
ensemble.add_model('gb', GradientBoostingRegressor(n_estimators=50), weight=1)

ensemble.fit(X_train, y_train)
y_pred_ensemble = ensemble.predict(X_test)

print(f"Ensemble RÂ²: {r2_score(y_test, y_pred_ensemble):.3f}")
```

## Ù…Ø§ÚˆÙ„ Ù…ÙˆØ§Ø²Ù†Û

```python
def compare_models(y_test, predictions_dict):
    """
    Ù…Ø§ÚˆÙ„Ø² Ú©Ø§ Ù…ÙˆØ§Ø²Ù†Û
    """
    results = []
    
    for name, y_pred in predictions_dict.items():
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        
        results.append({
            'Ù…Ø§ÚˆÙ„': name,
            'RÂ²': f"{r2:.3f}",
            'RMSE': f"{rmse:.2f}"
        })
    
    return pd.DataFrame(results)

# Ù…ÙˆØ§Ø²Ù†Û
predictions = {
    'Random Forest': y_pred_rf,
    'Gradient Boosting': y_pred_gb,
    'Neural Network': y_pred_nn,
    'Ensemble': y_pred_ensemble
}

comparison = compare_models(y_test, predictions)
print("\nÙ…Ø§ÚˆÙ„Ø² Ú©Ø§ Ù…ÙˆØ§Ø²Ù†Û:")
print(comparison.to_string(index=False))
```

## Ù¾ÛŒØ¯Ø§ÙˆØ§Ø± Ù¾ÛŒØ´ Ú¯ÙˆØ¦ÛŒ API

```python
class YieldPredictor:
    def __init__(self, model, scaler=None):
        self.model = model
        self.scaler = scaler
    
    def predict(self, field_data):
        """
        ÙÛŒÙ„Úˆ ÚˆÛŒÙ¹Ø§ Ø³Û’ Ù¾ÛŒØ¯Ø§ÙˆØ§Ø± Ù¾ÛŒØ´ Ú¯ÙˆØ¦ÛŒ
        """
        features = np.array([[
            field_data['temperature'],
            field_data['rainfall'],
            field_data['humidity'],
            field_data['soil_ph'],
            field_data['nitrogen'],
            field_data['phosphorus'],
            field_data['potassium'],
            field_data['ndvi']
        ]])
        
        if self.scaler:
            features = self.scaler.transform(features)
        
        prediction = self.model.predict(features)[0]
        
        return {
            'predicted_yield': round(prediction, 2),
            'unit': 'Ú©ÙˆØ¦Ù†Ù¹Ù„/Ø§ÛŒÚ©Ú‘',
            'confidence': 'Ø¯Ø±Ù…ÛŒØ§Ù†ÛŒ'
        }

# Ø§Ø³ØªØ¹Ù…Ø§Ù„
predictor = YieldPredictor(rf_model)

field_info = {
    'temperature': 28,
    'rainfall': 150,
    'humidity': 65,
    'soil_ph': 6.5,
    'nitrogen': 80,
    'phosphorus': 40,
    'potassium': 60,
    'ndvi': 0.7
}

result = predictor.predict(field_info)
print(f"\nğŸ“Š Ù¾ÛŒØ´ Ú¯ÙˆØ¦ÛŒ: {result['predicted_yield']} {result['unit']}")
```

## Ø®Ù„Ø§ØµÛ

- Ù¾ÛŒØ¯Ø§ÙˆØ§Ø± Ù¾ÛŒØ´ Ú¯ÙˆØ¦ÛŒ Ú©Ø³Ø§Ù†ÙˆÚº Ú©ÛŒ Ù…Ø¯Ø¯ Ú©Ø±ØªÛŒ ÛÛ’
- Ù…ØªØ¹Ø¯Ø¯ Ù…Ø§ÚˆÙ„Ø² Ø¯Ø³ØªÛŒØ§Ø¨ ÛÛŒÚº
- Ø§Ù†Ø³Ù…Ø¨Ù„ Ù…Ø§ÚˆÙ„ Ø¨ÛØªØ± Ù†ØªØ§Ø¦Ø¬ Ø¯ÛŒØªØ§ ÛÛ’
- ÙÛŒÚ†Ø± Ø§Ù†Ø¬ÛŒÙ†Ø¦Ø±Ù†Ú¯ Ø§ÛÙ… ÛÛ’

## Ø§Ú¯Ù„Û’ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª

- [Ø³Ù…Ø§Ø±Ù¹ Ø¢Ø¨Ù¾Ø§Ø´ÛŒ](/docs/module-4/smart-irrigation)
