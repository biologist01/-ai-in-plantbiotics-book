"use strict";(self.webpackChunkplant_biotech_ai=self.webpackChunkplant_biotech_ai||[]).push([[2629],{6881:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"module-2/image-processing","title":"Image Acquisition and Preprocessing","description":"Introduction to Plant Image Analysis \ud83c\udf31","source":"@site/docs-hardware/module-2/image-processing.md","sourceDirName":"module-2","slug":"/module-2/image-processing","permalink":"/docs-hardware/module-2/image-processing","draft":false,"unlisted":false,"editUrl":"https://github.com/biologist01/-ai-in-plantbiotics-book/tree/main/website/docs-hardware/module-2/image-processing.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to Computer Vision in Agriculture","permalink":"/docs-hardware/module-2/cv-intro"},"next":{"title":"Deep Learning for Plant Disease Detection","permalink":"/docs-hardware/module-2/deep-learning-cnn"}}');var a=i(4848),s=i(8453);const o={sidebar_position:2},r="Image Acquisition and Preprocessing",l={},d=[{value:"Introduction to Plant Image Analysis \ud83c\udf31",id:"introduction-to-plant-image-analysis-",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"Image Enhancement and Noise Reduction",id:"image-enhancement-and-noise-reduction",level:3},{value:"Background Removal for Plant Isolation",id:"background-removal-for-plant-isolation",level:3},{value:"Color-Based Segmentation for Leaf Detection",id:"color-based-segmentation-for-leaf-detection",level:3},{value:"Morphological Operations",id:"morphological-operations",level:3},{value:"Edge Detection and Contour Analysis",id:"edge-detection-and-contour-analysis",level:3},{value:"Feature Extraction",id:"feature-extraction",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Image Enhancement and Noise Reduction",id:"image-enhancement-and-noise-reduction-1",level:3},{value:"Background Removal using Thresholding",id:"background-removal-using-thresholding",level:3},{value:"Color-Based Segmentation using K-Means Clustering",id:"color-based-segmentation-using-k-means-clustering",level:3},{value:"Morphological Operations",id:"morphological-operations-1",level:3},{value:"Edge Detection and Contour Analysis",id:"edge-detection-and-contour-analysis-1",level:3},{value:"Feature Extraction",id:"feature-extraction-1",level:3},{value:"Practical Applications in Agriculture/Plant Science",id:"practical-applications-in-agricultureplant-science",level:2},{value:"Best Practices and Common Pitfalls",id:"best-practices-and-common-pitfalls",level:2},{value:"Hands-on Example: Automated Leaf Segmentation",id:"hands-on-example-automated-leaf-segmentation",level:2},{value:"Summary Table",id:"summary-table",level:2},{value:"Next Steps and Further Reading",id:"next-steps-and-further-reading",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"image-acquisition-and-preprocessing",children:"Image Acquisition and Preprocessing"})}),"\n",(0,a.jsx)(n.h2,{id:"introduction-to-plant-image-analysis-",children:"Introduction to Plant Image Analysis \ud83c\udf31"}),"\n",(0,a.jsx)(n.p,{children:"The AI revolution in plant biotechnology has transformed the way we analyze and understand plant growth, development, and responses to environmental factors. One crucial aspect of this revolution is the use of image analysis techniques to extract valuable information from plant images. In this module, we will delve into the essential image preprocessing techniques for plant analysis, including filtering, segmentation, feature extraction, and background removal for robust plant phenotyping."}),"\n",(0,a.jsx)(n.p,{children:"Plant images can be acquired using various methods, such as cameras, drones, or satellite imaging. However, these images often contain noise, irrelevant background information, and varying lighting conditions, which can hinder accurate analysis. Therefore, image preprocessing is a critical step in plant image analysis. In this lesson, we will explore the key concepts, techniques, and practical applications of image preprocessing in plant biotechnology."}),"\n",(0,a.jsx)(n.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,a.jsx)(n.h3,{id:"image-enhancement-and-noise-reduction",children:"Image Enhancement and Noise Reduction"}),"\n",(0,a.jsx)(n.p,{children:"Image enhancement and noise reduction are essential steps in image preprocessing. These techniques aim to improve the quality of the image by removing noise, correcting for uneven lighting, and enhancing the contrast between different features."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Image Filtering"}),": Image filtering techniques, such as Gaussian filtering, can be used to reduce noise in images. These filters work by replacing each pixel value with a weighted average of neighboring pixel values."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Contrast Stretching"}),": Contrast stretching is a technique used to enhance the contrast of an image by stretching the range of pixel values."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"background-removal-for-plant-isolation",children:"Background Removal for Plant Isolation"}),"\n",(0,a.jsx)(n.p,{children:"Background removal is a critical step in plant image analysis, as it allows for the isolation of the plant from the surrounding environment. This can be achieved using various techniques, such as thresholding, edge detection, and segmentation."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Thresholding"}),": Thresholding involves converting an image into a binary image, where pixels with values above a certain threshold are set to one color (usually white), and pixels with values below the threshold are set to another color (usually black)."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Edge Detection"}),": Edge detection techniques, such as the Canny edge detector, can be used to identify the boundaries of the plant in the image."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"color-based-segmentation-for-leaf-detection",children:"Color-Based Segmentation for Leaf Detection"}),"\n",(0,a.jsx)(n.p,{children:"Color-based segmentation is a technique used to separate different features in an image based on their color. In plant image analysis, color-based segmentation can be used to detect leaves, stems, and other plant organs."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Color Thresholding"}),": Color thresholding involves selecting a specific range of colors in the image and setting all pixels within that range to one color."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"K-Means Clustering"}),": K-means clustering is a technique used to group similar pixels in an image into clusters based on their color."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"morphological-operations",children:"Morphological Operations"}),"\n",(0,a.jsx)(n.p,{children:"Morphological operations, such as erosion and dilation, are used to modify the shape and size of features in an image."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Erosion"}),": Erosion involves removing pixels from the edges of features in an image."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dilation"}),": Dilation involves adding pixels to the edges of features in an image."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"edge-detection-and-contour-analysis",children:"Edge Detection and Contour Analysis"}),"\n",(0,a.jsx)(n.p,{children:"Edge detection and contour analysis are used to identify the boundaries of features in an image."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Canny Edge Detector"}),": The Canny edge detector is a widely used edge detection algorithm that produces a binary image with edges marked as white pixels."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Contour Detection"}),": Contour detection involves identifying the boundaries of features in an image and storing them as a set of points."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"feature-extraction",children:"Feature Extraction"}),"\n",(0,a.jsx)(n.p,{children:"Feature extraction involves extracting relevant information from an image, such as color histograms, texture, and shape."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Color Histograms"}),": Color histograms are a representation of the distribution of colors in an image."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Texture Analysis"}),": Texture analysis involves extracting features that describe the texture of an image, such as contrast, correlation, and entropy."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Shape Analysis"}),": Shape analysis involves extracting features that describe the shape of an image, such as area, perimeter, and eccentricity."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,a.jsx)(n.h3,{id:"image-enhancement-and-noise-reduction-1",children:"Image Enhancement and Noise Reduction"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import io, filters\n\n# Load the image\nimg = io.imread('plant_image.jpg')\n\n# Apply Gaussian filter to reduce noise\nfiltered_img = filters.gaussian(img, sigma=1)\n\n# Display the original and filtered images\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nax[0].imshow(img)\nax[0].set_title('Original Image')\nax[1].imshow(filtered_img)\nax[1].set_title('Filtered Image')\nplt.show()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"background-removal-using-thresholding",children:"Background Removal using Thresholding"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import io\n\n# Load the image\nimg = io.imread('plant_image.jpg')\n\n# Convert the image to grayscale\ngray_img = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])\n\n# Apply thresholding to separate the plant from the background\nthresh = np.mean(gray_img)\nbinary_img = np.where(gray_img > thresh, 255, 0)\n\n# Display the original and binary images\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nax[0].imshow(img)\nax[0].set_title('Original Image')\nax[1].imshow(binary_img, cmap='gray')\nax[1].set_title('Binary Image')\nplt.show()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"color-based-segmentation-using-k-means-clustering",children:"Color-Based Segmentation using K-Means Clustering"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import io\nfrom sklearn.cluster import KMeans\n\n# Load the image\nimg = io.imread('plant_image.jpg')\n\n# Reshape the image into a feature matrix\nX = img.reshape((-1, 3))\n\n# Apply K-means clustering to segment the image\nkmeans = KMeans(n_clusters=5)\nkmeans.fit(X)\n\n# Display the segmented image\nseg_img = kmeans.labels_.reshape(img.shape[:2])\nfig, ax = plt.subplots(figsize=(5, 5))\nax.imshow(seg_img, cmap='jet')\nax.set_title('Segmented Image')\nplt.show()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"morphological-operations-1",children:"Morphological Operations"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import io, morphology\n\n# Load the image\nimg = io.imread('plant_image.jpg')\n\n# Apply erosion to remove pixels from the edges of features\neroded_img = morphology.erosion(img, morphology.disk(3))\n\n# Apply dilation to add pixels to the edges of features\ndilated_img = morphology.dilation(img, morphology.disk(3))\n\n# Display the original, eroded, and dilated images\nfig, ax = plt.subplots(1, 3, figsize=(15, 5))\nax[0].imshow(img)\nax[0].set_title('Original Image')\nax[1].imshow(eroded_img)\nax[1].set_title('Eroded Image')\nax[2].imshow(dilated_img)\nax[2].set_title('Dilated Image')\nplt.show()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"edge-detection-and-contour-analysis-1",children:"Edge Detection and Contour Analysis"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import io, filters\n\n# Load the image\nimg = io.imread('plant_image.jpg')\n\n# Apply Canny edge detection to identify the boundaries of features\nedges = filters.canny(img, sigma=1)\n\n# Display the original and edge-detected images\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nax[0].imshow(img)\nax[0].set_title('Original Image')\nax[1].imshow(edges, cmap='gray')\nax[1].set_title('Edge-Detected Image')\nplt.show()\n"})}),"\n",(0,a.jsx)(n.h3,{id:"feature-extraction-1",children:"Feature Extraction"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import io\nfrom skimage.feature import hog\n\n# Load the image\nimg = io.imread('plant_image.jpg')\n\n# Convert the image to grayscale\ngray_img = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])\n\n# Extract HOG features from the image\nhog_features = hog(gray_img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(3, 3), block_norm='L2-Hys')\n\n# Display the HOG features\nfig, ax = plt.subplots(figsize=(5, 5))\nax.bar(range(len(hog_features)), hog_features)\nax.set_title('HOG Features')\nplt.show()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"practical-applications-in-agricultureplant-science",children:"Practical Applications in Agriculture/Plant Science"}),"\n",(0,a.jsx)(n.p,{children:"Image preprocessing techniques have numerous practical applications in agriculture and plant science, including:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Plant Phenotyping"}),": Image preprocessing can be used to extract features from plant images, such as leaf area, stem length, and root depth, which can be used to phenotype plants and identify desirable traits."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Disease Detection"}),": Image preprocessing can be used to detect diseases in plants, such as fungal infections, bacterial spots, and viral infections, by analyzing the texture, color, and shape of leaves and stems."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Weed Detection"}),": Image preprocessing can be used to detect weeds in crops, such as corn, soybeans, and wheat, by analyzing the texture, color, and shape of leaves and stems."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Yield Prediction"}),": Image preprocessing can be used to predict crop yields by analyzing the size, shape, and color of fruits and vegetables."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"best-practices-and-common-pitfalls",children:"Best Practices and Common Pitfalls"}),"\n",(0,a.jsx)(n.p,{children:"When working with image preprocessing techniques in plant biotechnology, it is essential to keep the following best practices and common pitfalls in mind:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Data Quality"}),": Ensure that the images are of high quality and are acquired under controlled conditions to minimize variability."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Image Preprocessing"}),": Apply image preprocessing techniques, such as filtering, thresholding, and segmentation, to enhance the quality of the images and remove noise."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Feature Extraction"}),": Extract relevant features from the images, such as color histograms, texture, and shape, to describe the plants and their characteristics."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Model Selection"}),": Select the most suitable machine learning model for the specific application, such as classification, regression, or clustering."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Overfitting"}),": Avoid overfitting by using techniques, such as cross-validation, regularization, and early stopping, to prevent the model from becoming too complex and fitting the noise in the data."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"hands-on-example-automated-leaf-segmentation",children:"Hands-on Example: Automated Leaf Segmentation"}),"\n",(0,a.jsx)(n.p,{children:"In this hands-on example, we will use image preprocessing techniques to segment leaves from a plant image."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import io, filters, morphology\n\n# Load the image\nimg = io.imread('plant_image.jpg')\n\n# Convert the image to grayscale\ngray_img = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])\n\n# Apply thresholding to separate the leaves from the background\nthresh = np.mean(gray_img)\nbinary_img = np.where(gray_img > thresh, 255, 0)\n\n# Apply morphological operations to remove noise and fill gaps\neroded_img = morphology.erosion(binary_img, morphology.disk(3))\ndilated_img = morphology.dilation(eroded_img, morphology.disk(3))\n\n# Display the original and segmented images\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nax[0].imshow(img)\nax[0].set_title('Original Image')\nax[1].imshow(dilated_img, cmap='gray')\nax[1].set_title('Segmented Image')\nplt.show()\n"})}),"\n",(0,a.jsx)(n.h2,{id:"summary-table",children:"Summary Table"}),"\n",(0,a.jsx)(n.p,{children:"The following table summarizes the key concepts and techniques covered in this lesson:"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Technique"}),(0,a.jsx)(n.th,{children:"Description"}),(0,a.jsx)(n.th,{children:"Application"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Image Enhancement"}),(0,a.jsx)(n.td,{children:"Improve image quality by reducing noise and enhancing contrast"}),(0,a.jsx)(n.td,{children:"Plant phenotyping, disease detection"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Background Removal"}),(0,a.jsx)(n.td,{children:"Separate the plant from the background"}),(0,a.jsx)(n.td,{children:"Plant phenotyping, yield prediction"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Color-Based Segmentation"}),(0,a.jsx)(n.td,{children:"Segment features based on color"}),(0,a.jsx)(n.td,{children:"Leaf detection, fruit detection"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Morphological Operations"}),(0,a.jsx)(n.td,{children:"Modify the shape and size of features"}),(0,a.jsx)(n.td,{children:"Leaf segmentation, stem detection"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Edge Detection"}),(0,a.jsx)(n.td,{children:"Identify the boundaries of features"}),(0,a.jsx)(n.td,{children:"Leaf boundary detection, stem detection"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Contour Analysis"}),(0,a.jsx)(n.td,{children:"Analyze the shape and size of features"}),(0,a.jsx)(n.td,{children:"Leaf shape analysis, fruit shape analysis"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Feature Extraction"}),(0,a.jsx)(n.td,{children:"Extract relevant features from images"}),(0,a.jsx)(n.td,{children:"Plant phenotyping, disease detection, yield prediction"})]})]})]}),"\n",(0,a.jsx)(n.h2,{id:"next-steps-and-further-reading",children:"Next Steps and Further Reading"}),"\n",(0,a.jsx)(n.p,{children:"For further reading and exploration, we recommend the following resources:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Scikit-Image"}),": A Python library for image processing and analysis."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"OpenCV"}),": A computer vision library with a wide range of tools and techniques for image and video analysis."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Plant Phenomics"}),": A field of research that focuses on the analysis of plant growth, development, and responses to environmental factors using image analysis and other techniques."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Computer Vision for Plant Phenotyping"}),": A book that provides an overview of computer vision techniques for plant phenotyping and analysis."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"By mastering the techniques and concepts covered in this lesson, you will be well-equipped to tackle a wide range of applications in plant biotechnology and agriculture, from plant phenotyping and disease detection to yield prediction and precision agriculture. \ud83d\udca1"}),"\n",(0,a.jsx)(n.p,{children:"Remember to always keep in mind the best practices and common pitfalls when working with image preprocessing techniques in plant biotechnology, and don't hesitate to explore further resources and references to deepen your understanding of these topics. \ud83c\udf31"}),"\n",(0,a.jsx)(n.p,{children:"We hope you found this lesson informative and engaging! If you have any questions or need further clarification on any of the concepts, don't hesitate to ask. \u26a0\ufe0f"})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>r});var t=i(6540);const a={},s=t.createContext(a);function o(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);