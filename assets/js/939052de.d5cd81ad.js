"use strict";(self.webpackChunkplant_biotech_ai=self.webpackChunkplant_biotech_ai||[]).push([[4264],{950:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>m,frontMatter:()=>s,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"module-1/data-preprocessing","title":"Data Preprocessing for Plant Science","description":"Data preprocessing is the foundation of successful machine learning in plant science. Raw agricultural data is often messy, incomplete, and inconsistent. This lesson teaches you how to transform raw data into clean, analysis-ready datasets.","source":"@site/docs-software/module-1/data-preprocessing.md","sourceDirName":"module-1","slug":"/module-1/data-preprocessing","permalink":"/-ai-in-plantbiotics-book/docs-software/module-1/data-preprocessing","draft":false,"unlisted":false,"editUrl":"https://github.com/biologist01/-ai-in-plantbiotics-book/tree/main/website/docs-software/module-1/data-preprocessing.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to Machine Learning for Plant Science","permalink":"/-ai-in-plantbiotics-book/docs-software/module-1/ml-intro"},"next":{"title":"Module 1: Classification Models for Plant Analysis","permalink":"/-ai-in-plantbiotics-book/docs-software/module-1/classification-models"}}');var r=a(4848),i=a(8453);const s={sidebar_position:2},l="Data Preprocessing for Plant Science",d={},o=[{value:"Why Preprocessing Matters",id:"why-preprocessing-matters",level:2},{value:"Common Data Issues in Agriculture",id:"common-data-issues-in-agriculture",level:2},{value:"1. Missing Data",id:"1-missing-data",level:3},{value:"2. Outliers",id:"2-outliers",level:3},{value:"3. Different Scales",id:"3-different-scales",level:3},{value:"Handling Missing Data",id:"handling-missing-data",level:2},{value:"Strategy 1: Remove Missing Data",id:"strategy-1-remove-missing-data",level:3},{value:"Strategy 2: Simple Imputation",id:"strategy-2-simple-imputation",level:3},{value:"Strategy 3: Forward/Backward Fill",id:"strategy-3-forwardbackward-fill",level:3},{value:"Strategy 4: Interpolation",id:"strategy-4-interpolation",level:3},{value:"Strategy 5: Predictive Imputation",id:"strategy-5-predictive-imputation",level:3},{value:"Handling Outliers",id:"handling-outliers",level:2},{value:"Detection Methods",id:"detection-methods",level:3},{value:"1. Statistical Methods (Z-Score)",id:"1-statistical-methods-z-score",level:4},{value:"2. Interquartile Range (IQR)",id:"2-interquartile-range-iqr",level:4},{value:"3. Domain Knowledge",id:"3-domain-knowledge",level:4},{value:"Handling Outliers (Not Removing)",id:"handling-outliers-not-removing",level:3},{value:"Feature Scaling",id:"feature-scaling",level:2},{value:"Why Scale?",id:"why-scale",level:3},{value:"Method 1: Standardization (Z-Score Normalization)",id:"method-1-standardization-z-score-normalization",level:3},{value:"Method 2: Min-Max Normalization",id:"method-2-min-max-normalization",level:3},{value:"Method 3: Robust Scaling",id:"method-3-robust-scaling",level:3},{value:"Feature Engineering",id:"feature-engineering",level:2},{value:"Creating Meaningful Features",id:"creating-meaningful-features",level:3},{value:"1. Time-Based Features",id:"1-time-based-features",level:4},{value:"2. Aggregated Features",id:"2-aggregated-features",level:4},{value:"3. Interaction Features",id:"3-interaction-features",level:4},{value:"4. Domain-Specific Indices",id:"4-domain-specific-indices",level:4},{value:"Encoding Categorical Variables",id:"encoding-categorical-variables",level:2},{value:"One-Hot Encoding",id:"one-hot-encoding",level:3},{value:"Label Encoding",id:"label-encoding",level:3},{value:"Target Encoding",id:"target-encoding",level:3},{value:"Handling Imbalanced Data",id:"handling-imbalanced-data",level:2},{value:"Problem",id:"problem",level:3},{value:"Solution 1: Resampling",id:"solution-1-resampling",level:3},{value:"Solution 2: Class Weights",id:"solution-2-class-weights",level:3},{value:"Complete Preprocessing Pipeline",id:"complete-preprocessing-pipeline",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"1. <strong>Understand Your Data First</strong>",id:"1-understand-your-data-first",level:3},{value:"2. <strong>Split Before Preprocessing</strong>",id:"2-split-before-preprocessing",level:3},{value:"3. <strong>Document All Steps</strong>",id:"3-document-all-steps",level:3},{value:"4. <strong>Validate Results</strong>",id:"4-validate-results",level:3},{value:"Real-World Example: Wheat Yield Prediction",id:"real-world-example-wheat-yield-prediction",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"data-preprocessing-for-plant-science",children:"Data Preprocessing for Plant Science"})}),"\n",(0,r.jsx)(n.p,{children:"Data preprocessing is the foundation of successful machine learning in plant science. Raw agricultural data is often messy, incomplete, and inconsistent. This lesson teaches you how to transform raw data into clean, analysis-ready datasets."}),"\n",(0,r.jsx)(n.h2,{id:"why-preprocessing-matters",children:"Why Preprocessing Matters"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Real-world scenario"}),": You have sensor data from 100 tomato plants over 90 days. The dataset has:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"15% missing values (sensor failures)"}),"\n",(0,r.jsx)(n.li,{children:"Outliers (temperature spikes from direct sunlight)"}),"\n",(0,r.jsx)(n.li,{children:"Different scales (temperature in \xb0C, humidity in %)"}),"\n",(0,r.jsx)(n.li,{children:"Noise from environmental interference"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Without proper preprocessing"}),", your ML model will learn from errors instead of patterns."]}),"\n",(0,r.jsx)(n.h2,{id:"common-data-issues-in-agriculture",children:"Common Data Issues in Agriculture"}),"\n",(0,r.jsx)(n.h3,{id:"1-missing-data",children:"1. Missing Data"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Causes:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Sensor failures or disconnections"}),"\n",(0,r.jsx)(n.li,{children:"Weather station downtime"}),"\n",(0,r.jsx)(n.li,{children:"Manual data entry errors"}),"\n",(0,r.jsx)(n.li,{children:"Network connectivity issues"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import pandas as pd\nimport numpy as np\n\n# Sample data with missing values\ndata = pd.DataFrame({\n    'plant_id': [1, 2, 3, 4, 5],\n    'height_cm': [45.2, np.nan, 52.1, 48.3, np.nan],\n    'leaf_count': [12, 15, np.nan, 14, 16],\n    'soil_moisture': [0.35, 0.42, 0.38, np.nan, 0.40]\n})\n\nprint(\"Missing values per column:\")\nprint(data.isnull().sum())\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Output:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"plant_id        0\nheight_cm       2\nleaf_count      1\nsoil_moisture   1\n"})}),"\n",(0,r.jsx)(n.h3,{id:"2-outliers",children:"2. Outliers"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Causes:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Sensor calibration drift"}),"\n",(0,r.jsx)(n.li,{children:"Physical damage to sensors"}),"\n",(0,r.jsx)(n.li,{children:"Extreme weather events"}),"\n",(0,r.jsx)(n.li,{children:"Data entry mistakes"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Detection:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import matplotlib.pyplot as plt\n\n# Temperature data with outlier\ntemperatures = [22, 23, 24, 22, 23, 95, 24, 23, 22]  # 95\xb0C is outlier\n\nplt.boxplot(temperatures)\nplt.ylabel('Temperature (\xb0C)')\nplt.title('Temperature Data with Outlier')\nplt.show()\n"})}),"\n",(0,r.jsx)(n.h3,{id:"3-different-scales",children:"3. Different Scales"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Problem"}),": ML algorithms sensitive to feature magnitudes."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"data = pd.DataFrame({\n    'temperature_celsius': [22, 24, 26],      # Range: 20-30\n    'humidity_percent': [65, 70, 75],         # Range: 40-100\n    'soil_nitrogen_ppm': [45, 50, 48]         # Range: 0-200\n})\n\n# Different ranges affect model training!\n"})}),"\n",(0,r.jsx)(n.h2,{id:"handling-missing-data",children:"Handling Missing Data"}),"\n",(0,r.jsx)(n.h3,{id:"strategy-1-remove-missing-data",children:"Strategy 1: Remove Missing Data"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": Small percentage of missing data (less than 5%)"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Remove rows with any missing values\ndata_clean = data.dropna()\n\n# Remove columns with many missing values\ndata_clean = data.dropna(axis=1, thresh=len(data)*0.7)  # Keep if <30% missing\n"})}),"\n",(0,r.jsx)(n.h3,{id:"strategy-2-simple-imputation",children:"Strategy 2: Simple Imputation"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": Random missing patterns"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from sklearn.impute import SimpleImputer\n\n# Mean imputation for numeric data\nimputer = SimpleImputer(strategy='mean')\ndata[['height_cm', 'soil_moisture']] = imputer.fit_transform(\n    data[['height_cm', 'soil_moisture']]\n)\n\n# Mode imputation for categorical data\nimputer_cat = SimpleImputer(strategy='most_frequent')\ndata[['plant_variety']] = imputer_cat.fit_transform(data[['plant_variety']])\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Strategies:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"mean"}),": Average value (for normal distributions)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"median"}),": Middle value (robust to outliers)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"most_frequent"}),": Mode (for categorical data)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"constant"}),": Specific value (e.g., 0)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"strategy-3-forwardbackward-fill",children:"Strategy 3: Forward/Backward Fill"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": Time-series data"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Carry last observation forward\ndata['soil_moisture'] = data['soil_moisture'].fillna(method='ffill')\n\n# Use next observation\ndata['soil_moisture'] = data['soil_moisture'].fillna(method='bfill')\n"})}),"\n",(0,r.jsx)(n.h3,{id:"strategy-4-interpolation",children:"Strategy 4: Interpolation"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": Smooth time-series data"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Linear interpolation\ndata['height_cm'] = data['height_cm'].interpolate(method='linear')\n\n# Time-based interpolation\ndata['timestamp'] = pd.to_datetime(data['timestamp'])\ndata = data.set_index('timestamp')\ndata['temperature'] = data['temperature'].interpolate(method='time')\n"})}),"\n",(0,r.jsx)(n.h3,{id:"strategy-5-predictive-imputation",children:"Strategy 5: Predictive Imputation"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": Complex patterns, enough data"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n# Use other features to predict missing values\nimputer = IterativeImputer(max_iter=10, random_state=42)\ndata_imputed = imputer.fit_transform(data)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"handling-outliers",children:"Handling Outliers"}),"\n",(0,r.jsx)(n.h3,{id:"detection-methods",children:"Detection Methods"}),"\n",(0,r.jsx)(n.h4,{id:"1-statistical-methods-z-score",children:"1. Statistical Methods (Z-Score)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from scipy import stats\nimport numpy as np\n\ndef remove_outliers_zscore(data, column, threshold=3):\n    """Remove outliers using z-score method"""\n    z_scores = np.abs(stats.zscore(data[column]))\n    return data[z_scores < threshold]\n\n# Apply\ndata_clean = remove_outliers_zscore(data, \'temperature\', threshold=3)\n'})}),"\n",(0,r.jsx)(n.h4,{id:"2-interquartile-range-iqr",children:"2. Interquartile Range (IQR)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def remove_outliers_iqr(data, column):\n    """Remove outliers using IQR method"""\n    Q1 = data[column].quantile(0.25)\n    Q3 = data[column].quantile(0.75)\n    IQR = Q3 - Q1\n    \n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    \n    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n\n# Apply\ndata_clean = remove_outliers_iqr(data, \'soil_nitrogen\')\n'})}),"\n",(0,r.jsx)(n.h4,{id:"3-domain-knowledge",children:"3. Domain Knowledge"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Best approach"}),": Use agricultural expertise!"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Define realistic bounds based on plant biology\ndef remove_outliers_domain(data):\n    \"\"\"Remove outliers using domain knowledge\"\"\"\n    return data[\n        (data['temperature'] >= 5) & (data['temperature'] <= 45) &  # \xb0C\n        (data['humidity'] >= 20) & (data['humidity'] <= 100) &      # %\n        (data['soil_moisture'] >= 0) & (data['soil_moisture'] <= 1) # Ratio\n    ]\n"})}),"\n",(0,r.jsx)(n.h3,{id:"handling-outliers-not-removing",children:"Handling Outliers (Not Removing)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Cap at percentiles\ndata['temperature'] = data['temperature'].clip(\n    lower=data['temperature'].quantile(0.05),\n    upper=data['temperature'].quantile(0.95)\n)\n\n# Log transformation for skewed data\ndata['yield_log'] = np.log1p(data['yield'])\n"})}),"\n",(0,r.jsx)(n.h2,{id:"feature-scaling",children:"Feature Scaling"}),"\n",(0,r.jsx)(n.h3,{id:"why-scale",children:"Why Scale?"}),"\n",(0,r.jsx)(n.p,{children:"Many ML algorithms (SVM, Neural Networks, K-Means) are sensitive to feature magnitudes."}),"\n",(0,r.jsx)(n.h3,{id:"method-1-standardization-z-score-normalization",children:"Method 1: Standardization (Z-Score Normalization)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Formula"}),": z = (x - \u03bc) / \u03c3"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Result"}),": Mean = 0, Std = 1"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data[['temperature', 'humidity', 'nitrogen']])\n\nprint(\"Mean:\", scaled_data.mean(axis=0))  # ~[0, 0, 0]\nprint(\"Std:\", scaled_data.std(axis=0))    # ~[1, 1, 1]\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": Features follow normal distribution"]}),"\n",(0,r.jsx)(n.h3,{id:"method-2-min-max-normalization",children:"Method 2: Min-Max Normalization"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Formula"}),": ",(0,r.jsx)(n.code,{children:"x_norm = (x - x_min) / (x_max - x_min)"})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Result"}),": Range = [0, 1]"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(data[['temperature', 'humidity']])\n\nprint(\"Min:\", scaled_data.min(axis=0))  # [0, 0]\nprint(\"Max:\", scaled_data.max(axis=0))  # [1, 1]\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": Need specific range, neural networks"]}),"\n",(0,r.jsx)(n.h3,{id:"method-3-robust-scaling",children:"Method 3: Robust Scaling"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Uses"}),": Median and IQR (robust to outliers)"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\nscaled_data = scaler.fit_transform(data[['yield', 'plant_height']])\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": Data has outliers"]}),"\n",(0,r.jsx)(n.h2,{id:"feature-engineering",children:"Feature Engineering"}),"\n",(0,r.jsx)(n.h3,{id:"creating-meaningful-features",children:"Creating Meaningful Features"}),"\n",(0,r.jsx)(n.h4,{id:"1-time-based-features",children:"1. Time-Based Features"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Convert to datetime\ndata['timestamp'] = pd.to_datetime(data['timestamp'])\n\n# Extract features\ndata['day_of_year'] = data['timestamp'].dt.dayofyear\ndata['week_of_year'] = data['timestamp'].dt.isocalendar().week\ndata['month'] = data['timestamp'].dt.month\ndata['is_growing_season'] = data['month'].isin([4, 5, 6, 7, 8, 9])\n\n# Growing degree days (GDD)\ndata['gdd'] = np.maximum(data['avg_temp'] - 10, 0)  # Base temp 10\xb0C\n"})}),"\n",(0,r.jsx)(n.h4,{id:"2-aggregated-features",children:"2. Aggregated Features"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Rolling averages (smooth noisy data)\ndata['temp_7day_avg'] = data['temperature'].rolling(window=7).mean()\ndata['rainfall_30day_sum'] = data['rainfall'].rolling(window=30).sum()\n\n# Growth rates\ndata['height_growth_rate'] = data['height'].diff() / data['days'].diff()\n"})}),"\n",(0,r.jsx)(n.h4,{id:"3-interaction-features",children:"3. Interaction Features"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Combine features that interact\ndata['heat_moisture_index'] = data['temperature'] * data['humidity'] / 100\ndata['light_temp_ratio'] = data['light_hours'] / (data['temperature'] + 1)\n\n# Polynomial features\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=2, include_bias=False)\npoly_features = poly.fit_transform(data[['nitrogen', 'phosphorus']])\n"})}),"\n",(0,r.jsx)(n.h4,{id:"4-domain-specific-indices",children:"4. Domain-Specific Indices"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Vegetation indices (from satellite/drone imagery)\ndata['ndvi'] = (data['nir'] - data['red']) / (data['nir'] + data['red'])\ndata['evi'] = 2.5 * (data['nir'] - data['red']) / (data['nir'] + 6*data['red'] - 7.5*data['blue'] + 1)\n\n# Stress indices\ndata['water_stress'] = 1 - (data['soil_moisture'] / data['field_capacity'])\ndata['nutrient_stress'] = data['optimal_n'] - data['current_n']\n"})}),"\n",(0,r.jsx)(n.h2,{id:"encoding-categorical-variables",children:"Encoding Categorical Variables"}),"\n",(0,r.jsx)(n.h3,{id:"one-hot-encoding",children:"One-Hot Encoding"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": Nominal categories (no order)"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Manual\ndata_encoded = pd.get_dummies(data, columns=['variety', 'soil_type'])\n\n# Using sklearn\nfrom sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\nencoded = encoder.fit_transform(data[['variety']])\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"variety_tomato    variety_pepper    variety_lettuce\n      1                 0                 0\n      0                 1                 0\n      0                 0                 1\n"})}),"\n",(0,r.jsx)(n.h3,{id:"label-encoding",children:"Label Encoding"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": Ordinal categories (have order)"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from sklearn.preprocessing import LabelEncoder\n\n# Disease severity: low < medium < high\nencoder = LabelEncoder()\ndata['severity_encoded'] = encoder.fit_transform(data['disease_severity'])\n\n# Output: low=0, medium=1, high=2\n"})}),"\n",(0,r.jsx)(n.h3,{id:"target-encoding",children:"Target Encoding"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"When to use"}),": High cardinality categorical features"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Mean encoding (use with caution - can leak info!)\nvariety_means = data.groupby('variety')['yield'].mean()\ndata['variety_encoded'] = data['variety'].map(variety_means)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"handling-imbalanced-data",children:"Handling Imbalanced Data"}),"\n",(0,r.jsx)(n.h3,{id:"problem",children:"Problem"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Disease detection dataset\nprint(data['disease'].value_counts())\n# healthy:    9500 (95%)\n# diseased:    500 (5%)\n\n# Model will predict \"healthy\" for everything!\n"})}),"\n",(0,r.jsx)(n.h3,{id:"solution-1-resampling",children:"Solution 1: Resampling"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Oversample minority class\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\n# Undersample majority class\nundersampler = RandomUnderSampler(random_state=42)\nX_resampled, y_resampled = undersampler.fit_resample(X, y)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"solution-2-class-weights",children:"Solution 2: Class Weights"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from sklearn.ensemble import RandomForestClassifier\n\n# Automatically balance class weights\nmodel = RandomForestClassifier(class_weight='balanced')\nmodel.fit(X_train, y_train)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"complete-preprocessing-pipeline",children:"Complete Preprocessing Pipeline"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n# Define preprocessing for numeric columns\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\n# Define preprocessing for categorical columns\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Combine preprocessing steps\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, ['temperature', 'humidity', 'nitrogen']),\n        ('cat', categorical_transformer, ['variety', 'soil_type'])\n    ])\n\n# Create full pipeline with model\nfrom sklearn.ensemble import RandomForestRegressor\n\nfull_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', RandomForestRegressor())\n])\n\n# Train\nfull_pipeline.fit(X_train, y_train)\n\n# Predict (preprocessing happens automatically!)\npredictions = full_pipeline.predict(X_test)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,r.jsxs)(n.h3,{id:"1-understand-your-data-first",children:["1. ",(0,r.jsx)(n.strong,{children:"Understand Your Data First"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Explore before preprocessing\nprint(data.describe())\nprint(data.info())\ndata.hist(bins=50, figsize=(20,15))\nplt.show()\n"})}),"\n",(0,r.jsxs)(n.h3,{id:"2-split-before-preprocessing",children:["2. ",(0,r.jsx)(n.strong,{children:"Split Before Preprocessing"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# WRONG: Fit on all data (data leakage!)\nscaler.fit(data)\n\n# CORRECT: Fit only on training data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n"})}),"\n",(0,r.jsxs)(n.h3,{id:"3-document-all-steps",children:["3. ",(0,r.jsx)(n.strong,{children:"Document All Steps"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Keep track of preprocessing decisions\npreprocessing_log = {\n    'missing_values': 'median imputation',\n    'outliers': 'IQR method, removed 2%',\n    'scaling': 'StandardScaler',\n    'features_added': ['gdd', 'ndvi', 'temp_7day_avg'],\n    'features_removed': ['sensor_id', 'field_notes']\n}\n"})}),"\n",(0,r.jsxs)(n.h3,{id:"4-validate-results",children:["4. ",(0,r.jsx)(n.strong,{children:"Validate Results"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Check preprocessing output\nassert not data_processed.isnull().any().any(), "Still have missing values!"\nassert data_processed[\'temperature\'].min() >= -5, "Unrealistic temperature"\nprint(f"Dataset shape: {data_processed.shape}")\nprint(f"Memory usage: {data_processed.memory_usage().sum() / 1024**2:.2f} MB")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"real-world-example-wheat-yield-prediction",children:"Real-World Example: Wheat Yield Prediction"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Load data\ndata = pd.read_csv('wheat_yield_data.csv')\n\n# 1. Handle missing values\nimputer = SimpleImputer(strategy='median')\nnumeric_cols = ['temperature', 'rainfall', 'soil_n', 'soil_p', 'soil_k']\ndata[numeric_cols] = imputer.fit_transform(data[numeric_cols])\n\n# 2. Remove outliers\ndata = data[data['yield'] < data['yield'].quantile(0.99)]\n\n# 3. Feature engineering\ndata['gdd'] = np.maximum(data['temperature'] - 10, 0)\ndata['rainfall_30d'] = data['rainfall'].rolling(30, min_periods=1).sum()\ndata['npk_ratio'] = data['soil_n'] / (data['soil_p'] + data['soil_k'] + 1)\n\n# 4. Split data\nfeatures = ['temperature', 'rainfall', 'soil_n', 'soil_p', 'soil_k', \n            'gdd', 'rainfall_30d', 'npk_ratio']\nX = data[features]\ny = data['yield']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# 5. Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# 6. Train model\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)\n\n# 7. Evaluate\ny_pred = model.predict(X_test_scaled)\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"RMSE: {rmse:.2f} tons/ha\")\nprint(f\"R\xb2: {r2:.3f}\")\n"})}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Task"}),(0,r.jsx)(n.th,{children:"Method"}),(0,r.jsx)(n.th,{children:"Use Case"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Missing Data"})}),(0,r.jsx)(n.td,{children:"Mean/Median Imputation"}),(0,r.jsx)(n.td,{children:"Random missing values"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"Forward/Backward Fill"}),(0,r.jsx)(n.td,{children:"Time-series"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"Predictive Imputation"}),(0,r.jsx)(n.td,{children:"Complex patterns"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Outliers"})}),(0,r.jsx)(n.td,{children:"Z-score"}),(0,r.jsx)(n.td,{children:"Normal distribution"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"IQR"}),(0,r.jsx)(n.td,{children:"Skewed distribution"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"Domain Knowledge"}),(0,r.jsx)(n.td,{children:"Always preferred!"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Scaling"})}),(0,r.jsx)(n.td,{children:"StandardScaler"}),(0,r.jsx)(n.td,{children:"Normal distribution"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"MinMaxScaler"}),(0,r.jsx)(n.td,{children:"Need [0,1] range"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"RobustScaler"}),(0,r.jsx)(n.td,{children:"Data has outliers"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Categorical"})}),(0,r.jsx)(n.td,{children:"One-Hot"}),(0,r.jsx)(n.td,{children:"Nominal categories"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{}),(0,r.jsx)(n.td,{children:"Label Encoding"}),(0,r.jsx)(n.td,{children:"Ordinal categories"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(n.p,{children:"Now that you can preprocess plant data, you're ready to build classification models!"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Continue to:"})," ",(0,r.jsx)(n.a,{href:"./classification-models",children:"Plant Classification Models \u2192"})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\ud83c\udf31 Good preprocessing = Good models!"})})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>s,x:()=>l});var t=a(6540);const r={},i=t.createContext(r);function s(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);